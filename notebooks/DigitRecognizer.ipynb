{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/56/0dbdae2a3c527a119bec0d5cf441655fe030ce1daa6fa6b9542f7dbd8664/tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 91kB/s s eta 0:00:01  |▏                               | 1.9MB 4.0MB/s eta 0:01:46     |▍                               | 5.7MB 4.0MB/s eta 0:01:45     |█▉                              | 24.7MB 16.2MB/s eta 0:00:25     |██                              | 26.0MB 16.2MB/s eta 0:00:25     |█████████▎                      | 122.8MB 63.4MB/s eta 0:00:05     |█████████████████████▌          | 283.9MB 35.5MB/s eta 0:00:04     |██████████████████████████████▉ | 407.1MB 64.0MB/s eta 0:00:01     |███████████████████████████████ | 409.3MB 64.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 23.3MB/s eta 0:00:01                            | 266kB 23.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1MB 20.5MB/s eta 0:00:01    |█████▏                          | 4.2MB 20.5MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 33.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 11.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Collecting numpy<2.0,>=1.16.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/0c/0261693cc3ad8e2b66e66dc2d2676a2cc17d3efb1c58a70db73754320e47/numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1MB 20.4MB/s eta 0:00:01    |█████                           | 3.2MB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.8.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/14/f5c294f1e36a031f165128c25feba93b3116f15a74398d0b2747ed75744f/protobuf-3.11.2-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 19.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/b3/0052e38c640d52b710e235b15821cc3c61d0065bf54e70a44550ef127349/grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4MB 29.9MB/s eta 0:00:01████▉                      | 747kB 29.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 12.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 13.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/5f/a1a02695b96d0e09c38abf7d1576b137979cea3d060d60891622cf61276d/google_auth-1.10.1-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (41.2.0)\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K     |████████████████████████████████| 327kB 26.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 17.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.8->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 20.2MB/s eta 0:00:01 eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 20.9MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/08/6a/abf83cb951617793fd49c98cb9456860f5df66ff89883c8660aa0672d425/cachetools-4.0.0-py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 11.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.1)\n",
      "Building wheels for collected packages: wrapt, termcolor, absl-py, gast, opt-einsum\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.2-cp37-cp37m-linux_x86_64.whl size=70707 sha256=f8489dbae3b2d94336339d220ad78cf3434dfac41f7af167b8aa86d723bfb7e9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4832 sha256=db90882ead082903ea96af1285d5ddde418408ab73f71cb3da58843aaae80d20\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121932 sha256=8f81629be9b0acb85cc7c9cd0bf0d792f032d5bee38bd8eae6b144eddcb1b703\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=867031641de71b1f0770f53714d3875513928d4c5ac42b990e7e0c3bd15b5c72\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp37-none-any.whl size=61682 sha256=c9aa3282ffcc54cdb9ffc4395df6df3850056a9ca3d5a4e47cf0ad894ec39a73\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
      "Successfully built wrapt termcolor absl-py gast opt-einsum\n",
      "Installing collected packages: pyasn1, pyasn1-modules, cachetools, rsa, google-auth, requests-oauthlib, google-auth-oauthlib, protobuf, werkzeug, grpcio, numpy, absl-py, markdown, tensorboard, h5py, keras-applications, wrapt, astor, scipy, termcolor, gast, opt-einsum, tensorflow-estimator, keras-preprocessing, google-pasta, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.10.1 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.18.1 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.0 scipy-1.4.1 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 werkzeug-0.16.0 wrapt-1.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 5.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 22.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3-cp37-cp37m-linux_x86_64.whl size=393351 sha256=dd9947b82656501124326c839e316ffe83cb34c0d655cca71b84d836719e3c47\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.3.1 pyyaml-5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4MB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 22.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.25.3 pytz-2019.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/42/3e92d7aa64295483fbca20a86c89b34d0cb43cffaadaffe028793902d790/matplotlib-3.1.2-cp37-cp37m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1MB 4.1MB/s eta 0:00:01    |███████████████████████▌        | 9.6MB 4.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 14.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
      "Installing collected packages: kiwisolver, pyparsing, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.2 pyparsing-2.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the train and the test datasets from the csv file and transform them into numpy arrays\n",
    "train_data = pandas.read_csv(\"../datasets/train.csv\").to_numpy()\n",
    "test_data = pandas.read_csv(\"../datasets/test.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have the data, as it's from 0..255, we want to make those values between 0 to 1\n",
    "#doing this, it's easier for the neuronal network to learn\n",
    "train_data_normalized = tf.keras.utils.normalize(train_data)\n",
    "test_data_normalized = tf.keras.utils.normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length:  42000\n",
      "Test set length:  28000\n"
     ]
    }
   ],
   "source": [
    "#check the length of the dataset(to see how can we split the data for train/test)\n",
    "print(\"Train set length: \",len(train_data_normalized))\n",
    "print(\"Test set length: \", len(test_data_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the train_set/test_set(reprezents the pixels from the image) \n",
    "#and the train_set_label/test_set_label(represents the correct numbers)\n",
    "train_set = train_data_normalized[0:42000,1:]\n",
    "train_set_label = train_data[0:42000,0]\n",
    "\n",
    "test_set = test_data_normalized[0:28000,1:]\n",
    "test_set_label = test_data[0:28000,0]\n",
    "\n",
    "#NOTE\n",
    "#As the data is normalized, the label was normalized as well. \n",
    "#We take the label value from the normal dataset(train_data/test_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the sequential 2d model\n",
    "#NOTE\n",
    "#in this case, our datasets are already flattened. We do not need to flattened it anymore\n",
    "model = tf.keras.models.Sequential()\n",
    "#now, we use a Dense(each input node is connected to each output node) layer with 128 neurons and \n",
    "#the activation function(this is what is gonna make the neuron to 'fire')\n",
    "\n",
    "#first, we will apply the dense layer with ReLU(f(x) = max(0, x)) as activation function\n",
    "#we will apply 2 dense layers.. enough for our data to not be under/overfitted\n",
    "model.add(tf.keras.layers.Dense(128, imput_dim=784, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, imput_dim=784, activation = tf.nn.relu))\n",
    "#now, add the last layer that has as activation function softmax. We use this because we need to change the received numbers\n",
    "#from the previour layer into probabilities\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining parameters used by the model to train the neural network\n",
    "#optimizer: the optimizer used\n",
    "#loss: the model will try it's best to minimize the loss.\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_set[30]\n",
    "img.shape=(28, 28)\n",
    "plt.imshow(255 - img,cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "train_set_label[30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
